<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>unet API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>unet</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import torch
import torch.nn as nn


def sinusoidal_embedding(n, d):
    &#34;&#34;&#34;
    Generates a sinusoidal embedding of size n x d.

    Parameters:
        n (int): The number of rows in the embedding.
        d (int): The number of columns in the embedding.

    Returns:
        torch.Tensor: The sinusoidal embedding of size n x d.
    &#34;&#34;&#34;
    # Returns the standard positional embedding
    embedding = torch.zeros(n, d)
    wk = torch.tensor([1 / 10_000 ** (2 * j / d) for j in range(d)])
    wk = wk.reshape((1, d))
    t = torch.arange(n).reshape((n, 1))
    embedding[:,::2] = torch.sin(t * wk[:,::2])
    embedding[:,1::2] = torch.cos(t * wk[:,::2])

    return embedding

class MyBlock(nn.Module):
    def __init__(self, shape, in_c, out_c, kernel_size=3, stride=1, padding=1, activation=None, normalize=True):
        &#34;&#34;&#34;
        Initializes a new instance of the MyBlock class.

        Parameters:
            shape (tuple): The shape of the input tensor.
            in_c (int): The number of input channels.
            out_c (int): The number of output channels.
            kernel_size (int, optional): The size of the convolutional kernel. Defaults to 3.
            stride (int, optional): The stride of the convolutional kernel. Defaults to 1.
            padding (int, optional): The padding of the convolutional kernel. Defaults to 1.
            activation (nn.Module, optional): The activation function to use. Defaults to None.
            normalize (bool, optional): Whether to apply layer normalization. Defaults to True.
        &#34;&#34;&#34;
        super(MyBlock, self).__init__()
        self.ln = nn.LayerNorm(shape)
        self.conv1 = nn.Conv2d(in_c, out_c, kernel_size, stride, padding)
        self.conv2 = nn.Conv2d(out_c, out_c, kernel_size, stride, padding)
        self.activation = nn.SiLU() if activation is None else activation
        self.normalize = normalize

    def forward(self, x):
        &#34;&#34;&#34;
        Forward pass of the model.

        Args:
            x (torch.Tensor): The input tensor.

        Returns:
            torch.Tensor: The output tensor after passing through the model.
        &#34;&#34;&#34;
        out = self.ln(x) if self.normalize else x
        out = self.conv1(out)
        out = self.activation(out)
        
        out = self.conv2(out)
        out = self.activation(out)  
              
        return out

    def _make_te(self, dim_in, dim_out):
        &#34;&#34;&#34;
        Creates a sequential neural network model with two linear layers and a SiLU activation function.

        Args:
            dim_in (int): The number of input features.
            dim_out (int): The number of output features.

        Returns:
            torch.nn.Sequential: The sequential neural network model.
        &#34;&#34;&#34;
        return nn.Sequential(
            nn.Linear(dim_in, dim_out),
            nn.SiLU(),
            nn.Linear(dim_out, dim_out)
        )

class MyUNet(nn.Module):
    def __init__(self, channel, size, n_steps=500, time_emb_dim=100):
        &#34;&#34;&#34;
        Initializes the MyUNet model, a U-Net architecture with customizable configurations for image segmentation tasks.
        
        This constructor initializes various layers and components based on the specified image size and configurations.
        It sets up a U-Net architecture with optional depth based on the &#39;size&#39; parameter which can be 128 or 256 pixels,
        and constructs blocks and transitional layers correspondingly. The architecture uses sinusoidal embeddings for time
        encoding and multiple encoding and decoding blocks with convolutional and transposed convolutional layers.
        
        Parameters:
        - channel (int): The number of channels in the input and output images. Typically, this corresponds to the
        number of color channels (e.g., 3 for RGB images).
        - size (int): The dimension of the input images (e.g., 128, 256 or 512 pixels). This size determines the depth and
        complexity of the U-Net architecture.
        - n_steps (int, optional): The number of steps or positions for the time embedding, with a default of 500. This
        is used in the sinusoidal time embedding.
        - time_emb_dim (int, optional): The dimensionality of the time embedding vector, with a default of 100.
        
        Raises:
        - ValueError: If the &#39;size&#39; parameter is not recognized (i.e., not 128, 256 or 512), a ValueError is raised.
        
        The network comprises several stages of downsampling followed by upsampling to create a symmetric architecture,
        with additional bottleneck layers. Time-dependent features are integrated at multiple levels of the network.
        &#34;&#34;&#34;
        super(MyUNet, self).__init__()
        self.size = size

        # Sinusoidal embedding
        self.time_embed = nn.Embedding(n_steps, time_emb_dim)
        self.time_embed.weight.data = sinusoidal_embedding(n_steps, time_emb_dim)
        self.time_embed.requires_grad_(False)
        
        
        if self.size == 128:
            # First half
            self.te1 = self._make_te(time_emb_dim, channel)
            self.b1 = nn.Sequential(
                MyBlock((channel, 128, 128), channel, 16),
                MyBlock((16, 128, 128), 16, 16)
            )
            self.down1 = nn.Conv2d(16, 32, 4, 2, 1) # 128x128 --&gt; 64x64

            self.te2 = self._make_te(time_emb_dim, 32)
            self.b2 = nn.Sequential(
                MyBlock((32, 64, 64), 32, 32),
                MyBlock((32, 64, 64), 32, 32)
            )
            self.down2 = nn.Conv2d(32, 64, 4, 2, 1) # 64x64 --&gt; 32x32

            self.te3 = self._make_te(time_emb_dim, 64)
            self.b3 = nn.Sequential(
                MyBlock((64, 32, 32), 64, 64),
                MyBlock((64, 32, 32), 64, 64)
            )
            self.down3 = nn.Conv2d(64, 128, 4, 2, 1) # 32x32 --&gt; 16x16

            self.te4 = self._make_te(time_emb_dim, 128)
            self.b4 = nn.Sequential(
                MyBlock((128, 16, 16), 128, 128),
                MyBlock((128, 16, 16), 128, 128)
            )
            self.down4 = nn.Conv2d(128, 256, 4, 2, 1) # 16x16 --&gt; 8x8

            self.te5 = self._make_te(time_emb_dim, 256)
            self.b5 = nn.Sequential(
                MyBlock((256, 8, 8), 256, 256),
                MyBlock((256, 8, 8), 256, 256)
            )
            self.down5 = nn.Sequential(
                nn.Conv2d(256, 256, 2, 1), # 8x8 --&gt; 7x7
                nn.SiLU(),
                nn.Conv2d(256, 512, 4, 2, 2) # 7x7 --&gt; 4x4
            )

            # Bottleneck
            self.te_mid = self._make_te(time_emb_dim, 512)
            self.b_mid = nn.Sequential(
                MyBlock((512, 4, 4), 512, 512),
                MyBlock((512, 4, 4), 512, 512),
                MyBlock((512, 4, 4), 512, 512)
            )

            # Second half
            self.up1 = nn.Sequential(
                nn.ConvTranspose2d(512, 512, 3, 2, 1), #4x4 --&gt; 7x7
                nn.SiLU(),
                nn.ConvTranspose2d(512, 256, 2, 1) #7x7 --&gt; 8x8
            )

            self.te7 = self._make_te(time_emb_dim, 512)
            self.b7 = nn.Sequential(
                MyBlock((512, 8, 8), 512, 256),
                MyBlock((256, 8, 8), 256, 128),
                MyBlock((128, 8, 8), 128, 128)
            )

            self.up2 = nn.ConvTranspose2d(128, 128, 4, 2, 1) #8x8 --&gt; 16x16
            self.te8 = self._make_te(time_emb_dim, 256)
            self.b8 = nn.Sequential(
                MyBlock((256, 16, 16), 256, 128),
                MyBlock((128, 16, 16), 128, 64),
                MyBlock((64, 16, 16), 64, 64)
            )

            self.up3 = nn.ConvTranspose2d(64, 64, 4, 2, 1) #16x16 --&gt; 32x32
            self.te9 = self._make_te(time_emb_dim, 128)
            self.b9 = nn.Sequential(
                MyBlock((128, 32, 32), 128, 64),
                MyBlock((64, 32, 32), 64, 32),
                MyBlock((32, 32, 32), 32, 32, normalize=False)
            )

            self.up4 = nn.ConvTranspose2d(32, 32, 4, 2, 1) #32x32 --&gt; 64x64
            self.te10 = self._make_te(time_emb_dim, 64) # 64 (out3) + 22 = 86
            self.b10 = nn.Sequential(
                MyBlock((64, 64, 64), 64, 32),
                MyBlock((32, 64, 64), 32, 16),
                MyBlock((16, 64, 64), 16, 16, normalize=False)
            )

            self.up5 = nn.ConvTranspose2d(16, 16, 4, 2, 1) #64x64 --&gt; 128x128
            self.te11 = self._make_te(time_emb_dim, 32) # 32 (out2) + 21 = 53
            self.b11 = nn.Sequential(
                MyBlock((32, 128, 128), 32, 16),
                MyBlock((16, 128, 128), 16, 8),
                MyBlock((8, 128, 128), 8, 8, normalize=False)
            )

            self.conv_out = nn.Conv2d(8, channel, 3, 1, 1)
        
        elif self.size == 256:
            # First half
            self.te1 = self._make_te(time_emb_dim, channel)
            self.b1 = nn.Sequential(
                MyBlock((channel, 256, 256), channel, 16),
                MyBlock((16, 256, 256), 16, 16)
            )
            self.down1 = nn.Conv2d(16, 32, 4, 2, 1) # 256x256 --&gt; 128x128

            self.te2 = self._make_te(time_emb_dim, 32)
            self.b2 = nn.Sequential(
                MyBlock((32, 128, 128), 32, 32),
                MyBlock((32, 128, 128), 32, 32)
            )
            self.down2 = nn.Conv2d(32, 64, 4, 2, 1) # 128x128 --&gt; 64x64

            self.te3 = self._make_te(time_emb_dim, 64)
            self.b3 = nn.Sequential(
                MyBlock((64, 64, 64), 64, 64),
                MyBlock((64, 64, 64), 64, 64)
            )
            self.down3 = nn.Conv2d(64, 128, 4, 2, 1) # 64x64 --&gt; 32x32

            self.te4 = self._make_te(time_emb_dim, 128)
            self.b4 = nn.Sequential(
                MyBlock((128, 32, 32), 128, 128),
                MyBlock((128, 32, 32), 128, 128)
            )
            self.down4 = nn.Conv2d(128, 256, 4, 2, 1) # 32x32 --&gt; 16x16
            
            self.te5 = self._make_te(time_emb_dim, 256)
            self.b5 = nn.Sequential(
                MyBlock((256, 16, 16), 256, 256),
                MyBlock((256, 16, 16), 256, 256)
            )
            self.down5 = nn.Conv2d(256, 512, 4, 2, 1) # 16x16 --&gt; 8x8

            self.te6 = self._make_te(time_emb_dim, 512)
            self.b6 = nn.Sequential(
                MyBlock((512, 8, 8), 512, 512),
                MyBlock((512, 8, 8), 512, 512)
            )
            self.down6 = nn.Sequential(
                nn.Conv2d(512, 512, 2, 1), # 8x8 --&gt; 7x7
                nn.SiLU(),
                nn.Conv2d(512, 1024, 4, 2, 2) # 7x7 --&gt; 4x4
            )

            # Bottleneck
            self.te_mid = self._make_te(time_emb_dim, 1024)
            self.b_mid = nn.Sequential(
                MyBlock((1024, 4, 4), 1024, 1024),
                MyBlock((1024, 4, 4), 1024, 1024),
                MyBlock((1024, 4, 4), 1024, 1024)
            )

            # Second half
            self.up1 = nn.Sequential(
                nn.ConvTranspose2d(1024, 512, 3, 2, 1), #4x4 --&gt; 7x7
                nn.SiLU(),
                nn.ConvTranspose2d(512, 512, 2, 1) #7x7 --&gt; 8x8
            )

            self.te7 = self._make_te(time_emb_dim, 1024)
            self.b7 = nn.Sequential(
                MyBlock((1024, 8, 8), 1024, 512),
                MyBlock((512, 8, 8), 512, 256),
                MyBlock((256, 8, 8), 256, 256)
            )

            self.up2 = nn.ConvTranspose2d(256, 256, 4, 2, 1) #8x8 --&gt; 16x16
            self.te8 = self._make_te(time_emb_dim, 512)
            self.b8 = nn.Sequential(
                MyBlock((512, 16, 16), 512, 256),
                MyBlock((256, 16, 16), 256, 128),
                MyBlock((128, 16, 16), 128, 128)
            )

            self.up3 = nn.ConvTranspose2d(128, 128, 4, 2, 1) #16x16 --&gt; 32x32
            self.te9 = self._make_te(time_emb_dim, 256)
            self.b9 = nn.Sequential(
                MyBlock((256, 32, 32), 256, 128),
                MyBlock((128, 32, 32), 128, 64),
                MyBlock((64, 32, 32), 64, 64, normalize=False)
            )

            self.up4 = nn.ConvTranspose2d(64, 64, 4, 2, 1) #32x32 --&gt; 64x64
            self.te10 = self._make_te(time_emb_dim, 128) # 64 (out3) + 22 = 86
            self.b10 = nn.Sequential(
                MyBlock((128, 64, 64), 128, 64),
                MyBlock((64, 64, 64), 64, 32),
                MyBlock((32, 64, 64), 32, 32, normalize=False)
            )

            self.up5 = nn.ConvTranspose2d(32, 32, 4, 2, 1) #64x64 --&gt; 128x128
            self.te11 = self._make_te(time_emb_dim, 64) # 32 (out2) + 21 = 53
            self.b11 = nn.Sequential(
                MyBlock((64, 128, 128), 64, 32),
                MyBlock((32, 128, 128), 32, 16),
                MyBlock((16, 128, 128), 16, 16, normalize=False)
            )
            
            self.up6 = nn.ConvTranspose2d(16, 16, 4, 2, 1) #64x64 --&gt; 128x128
            self.te12 = self._make_te(time_emb_dim, 32) # 32 (out2) + 21 = 53
            self.b12 = nn.Sequential(
                MyBlock((32, 256, 256), 32, 16),
                MyBlock((16, 256, 256), 16, 8),
                MyBlock((8, 256, 256), 8, 8, normalize=False)
            )

            self.conv_out = nn.Conv2d(8, channel, 3, 1, 1)
            
        else: 
            print(f&#34;Wrong size : {self.size}&#34;)

    def forward(self, x, t):
        &#34;&#34;&#34;
        Forward pass of the model.

        Args:
            x (torch.Tensor): The input tensor.
            t (torch.Tensor): The time tensor.

        Returns:
            torch.Tensor: The output tensor after passing through the model.
        &#34;&#34;&#34;
        t = self.time_embed(t)
        n = len(x)
        if self.size == 128:
            out1 = self.b1(x + self.te1(t).reshape(n, -1, 1, 1))        
            out2 = self.b2(self.down1(out1) + self.te2(t).reshape(n, -1, 1, 1))        
            out3 = self.b3(self.down2(out2) + self.te3(t).reshape(n, -1, 1, 1))        
            out4 = self.b4(self.down3(out3) + self.te4(t).reshape(n, -1, 1, 1))        
            out5 = self.b5(self.down4(out4) + self.te5(t).reshape(n, -1, 1, 1))
            
            out_mid = self.b_mid(self.down5(out5) + self.te_mid(t).reshape(n, -1, 1, 1))

            out7 = torch.cat((out5, self.up1(out_mid)), dim=1)
            out7 = self.b7(out7 + self.te7(t).reshape(n, -1, 1, 1))

            out8 = torch.cat((out4, self.up2(out7)), dim=1)
            out8 = self.b8(out8 + self.te8(t).reshape(n, -1, 1, 1))

            out9 = torch.cat((out3, self.up3(out8)), dim=1)
            out9 = self.b9(out9 + self.te9(t).reshape(n, -1, 1, 1))

            out10 = torch.cat((out2, self.up4(out9)), dim=1)
            out10 = self.b10(out10 + self.te10(t).reshape(n, -1, 1, 1))

            out11 = torch.cat((out1, self.up5(out10)), dim=1)
            out = self.b11(out11 + self.te11(t).reshape(n, -1, 1, 1))

            out = self.conv_out(out)

            return out
        
        elif self.size == 256:
            out1 = self.b1(x + self.te1(t).reshape(n, -1, 1, 1))        
            out2 = self.b2(self.down1(out1) + self.te2(t).reshape(n, -1, 1, 1))        
            out3 = self.b3(self.down2(out2) + self.te3(t).reshape(n, -1, 1, 1))        
            out4 = self.b4(self.down3(out3) + self.te4(t).reshape(n, -1, 1, 1))        
            out5 = self.b5(self.down4(out4) + self.te5(t).reshape(n, -1, 1, 1))
            out6 = self.b6(self.down5(out5) + self.te6(t).reshape(n, -1, 1, 1))
            
            out_mid = self.b_mid(self.down6(out6) + self.te_mid(t).reshape(n, -1, 1, 1))

            out7 = torch.cat((out6, self.up1(out_mid)), dim=1)
            out7 = self.b7(out7 + self.te7(t).reshape(n, -1, 1, 1))

            out8 = torch.cat((out5, self.up2(out7)), dim=1)
            out8 = self.b8(out8 + self.te8(t).reshape(n, -1, 1, 1))

            out9 = torch.cat((out4, self.up3(out8)), dim=1)
            out9 = self.b9(out9 + self.te9(t).reshape(n, -1, 1, 1))

            out10 = torch.cat((out3, self.up4(out9)), dim=1)
            out10 = self.b10(out10 + self.te10(t).reshape(n, -1, 1, 1))

            out11 = torch.cat((out2, self.up5(out10)), dim=1)
            out11 = self.b11(out11 + self.te11(t).reshape(n, -1, 1, 1))
            
            out12 = torch.cat((out1, self.up6(out11)), dim=1)
            out = self.b12(out12 + self.te12(t).reshape(n, -1, 1, 1))

            out = self.conv_out(out)

            return out

    def _make_te(self, dim_in, dim_out):
        &#34;&#34;&#34;
        Creates a sequential neural network model with two linear layers and a SiLU activation function.

        Args:
            dim_in (int): The number of input features.
            dim_out (int): The number of output features.

        Returns:
            torch.nn.Sequential: The sequential neural network model.
        &#34;&#34;&#34;
        return nn.Sequential(
            nn.Linear(dim_in, dim_out),
            nn.SiLU(),
            nn.Linear(dim_out, dim_out)
        )</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="unet.sinusoidal_embedding"><code class="name flex">
<span>def <span class="ident">sinusoidal_embedding</span></span>(<span>n, d)</span>
</code></dt>
<dd>
<div class="desc"><p>Generates a sinusoidal embedding of size n x d.</p>
<h2 id="parameters">Parameters</h2>
<p>n (int): The number of rows in the embedding.
d (int): The number of columns in the embedding.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>torch.Tensor</code></dt>
<dd>The sinusoidal embedding of size n x d.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sinusoidal_embedding(n, d):
    &#34;&#34;&#34;
    Generates a sinusoidal embedding of size n x d.

    Parameters:
        n (int): The number of rows in the embedding.
        d (int): The number of columns in the embedding.

    Returns:
        torch.Tensor: The sinusoidal embedding of size n x d.
    &#34;&#34;&#34;
    # Returns the standard positional embedding
    embedding = torch.zeros(n, d)
    wk = torch.tensor([1 / 10_000 ** (2 * j / d) for j in range(d)])
    wk = wk.reshape((1, d))
    t = torch.arange(n).reshape((n, 1))
    embedding[:,::2] = torch.sin(t * wk[:,::2])
    embedding[:,1::2] = torch.cos(t * wk[:,::2])

    return embedding</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="unet.MyBlock"><code class="flex name class">
<span>class <span class="ident">MyBlock</span></span>
<span>(</span><span>shape, in_c, out_c, kernel_size=3, stride=1, padding=1, activation=None, normalize=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>
<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As per the example above, an <code>__init__()</code> call to the parent class
must be made before assignment on the child.</p>
</div>
<p>:ivar training: Boolean represents whether this module is in training or
evaluation mode.
:vartype training: bool</p>
<p>Initializes a new instance of the MyBlock class.</p>
<h2 id="parameters">Parameters</h2>
<p>shape (tuple): The shape of the input tensor.
in_c (int): The number of input channels.
out_c (int): The number of output channels.
kernel_size (int, optional): The size of the convolutional kernel. Defaults to 3.
stride (int, optional): The stride of the convolutional kernel. Defaults to 1.
padding (int, optional): The padding of the convolutional kernel. Defaults to 1.
activation (nn.Module, optional): The activation function to use. Defaults to None.
normalize (bool, optional): Whether to apply layer normalization. Defaults to True.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class MyBlock(nn.Module):
    def __init__(self, shape, in_c, out_c, kernel_size=3, stride=1, padding=1, activation=None, normalize=True):
        &#34;&#34;&#34;
        Initializes a new instance of the MyBlock class.

        Parameters:
            shape (tuple): The shape of the input tensor.
            in_c (int): The number of input channels.
            out_c (int): The number of output channels.
            kernel_size (int, optional): The size of the convolutional kernel. Defaults to 3.
            stride (int, optional): The stride of the convolutional kernel. Defaults to 1.
            padding (int, optional): The padding of the convolutional kernel. Defaults to 1.
            activation (nn.Module, optional): The activation function to use. Defaults to None.
            normalize (bool, optional): Whether to apply layer normalization. Defaults to True.
        &#34;&#34;&#34;
        super(MyBlock, self).__init__()
        self.ln = nn.LayerNorm(shape)
        self.conv1 = nn.Conv2d(in_c, out_c, kernel_size, stride, padding)
        self.conv2 = nn.Conv2d(out_c, out_c, kernel_size, stride, padding)
        self.activation = nn.SiLU() if activation is None else activation
        self.normalize = normalize

    def forward(self, x):
        &#34;&#34;&#34;
        Forward pass of the model.

        Args:
            x (torch.Tensor): The input tensor.

        Returns:
            torch.Tensor: The output tensor after passing through the model.
        &#34;&#34;&#34;
        out = self.ln(x) if self.normalize else x
        out = self.conv1(out)
        out = self.activation(out)
        
        out = self.conv2(out)
        out = self.activation(out)  
              
        return out

    def _make_te(self, dim_in, dim_out):
        &#34;&#34;&#34;
        Creates a sequential neural network model with two linear layers and a SiLU activation function.

        Args:
            dim_in (int): The number of input features.
            dim_out (int): The number of output features.

        Returns:
            torch.nn.Sequential: The sequential neural network model.
        &#34;&#34;&#34;
        return nn.Sequential(
            nn.Linear(dim_in, dim_out),
            nn.SiLU(),
            nn.Linear(dim_out, dim_out)
        )</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="unet.MyBlock.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, x) ‑> Callable[..., Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Forward pass of the model.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>torch.Tensor</code></dt>
<dd>The input tensor.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>torch.Tensor</code></dt>
<dd>The output tensor after passing through the model.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward(self, x):
    &#34;&#34;&#34;
    Forward pass of the model.

    Args:
        x (torch.Tensor): The input tensor.

    Returns:
        torch.Tensor: The output tensor after passing through the model.
    &#34;&#34;&#34;
    out = self.ln(x) if self.normalize else x
    out = self.conv1(out)
    out = self.activation(out)
    
    out = self.conv2(out)
    out = self.activation(out)  
          
    return out</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="unet.MyUNet"><code class="flex name class">
<span>class <span class="ident">MyUNet</span></span>
<span>(</span><span>channel, size, n_steps=500, time_emb_dim=100)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>
<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As per the example above, an <code>__init__()</code> call to the parent class
must be made before assignment on the child.</p>
</div>
<p>:ivar training: Boolean represents whether this module is in training or
evaluation mode.
:vartype training: bool</p>
<p>Initializes the MyUNet model, a U-Net architecture with customizable configurations for image segmentation tasks.</p>
<p>This constructor initializes various layers and components based on the specified image size and configurations.
It sets up a U-Net architecture with optional depth based on the 'size' parameter which can be 128 or 256 pixels,
and constructs blocks and transitional layers correspondingly. The architecture uses sinusoidal embeddings for time
encoding and multiple encoding and decoding blocks with convolutional and transposed convolutional layers.</p>
<p>Parameters:
- channel (int): The number of channels in the input and output images. Typically, this corresponds to the
number of color channels (e.g., 3 for RGB images).
- size (int): The dimension of the input images (e.g., 128 or 256 pixels). This size determines the depth and
complexity of the U-Net architecture.
- n_steps (int, optional): The number of steps or positions for the time embedding, with a default of 500. This
is used in the sinusoidal time embedding.
- time_emb_dim (int, optional): The dimensionality of the time embedding vector, with a default of 100.</p>
<p>Raises:
- ValueError: If the 'size' parameter is not recognized (i.e., not 128 or 256), a ValueError is raised.</p>
<p>The network comprises several stages of downsampling followed by upsampling to create a symmetric architecture,
with additional bottleneck layers. Time-dependent features are integrated at multiple levels of the network.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class MyUNet(nn.Module):
    def __init__(self, channel, size, n_steps=500, time_emb_dim=100):
        &#34;&#34;&#34;
        Initializes the MyUNet model, a U-Net architecture with customizable configurations for image segmentation tasks.
        
        This constructor initializes various layers and components based on the specified image size and configurations.
        It sets up a U-Net architecture with optional depth based on the &#39;size&#39; parameter which can be 128 or 256 pixels,
        and constructs blocks and transitional layers correspondingly. The architecture uses sinusoidal embeddings for time
        encoding and multiple encoding and decoding blocks with convolutional and transposed convolutional layers.
        
        Parameters:
        - channel (int): The number of channels in the input and output images. Typically, this corresponds to the
        number of color channels (e.g., 3 for RGB images).
        - size (int): The dimension of the input images (e.g., 128 or 256 pixels). This size determines the depth and
        complexity of the U-Net architecture.
        - n_steps (int, optional): The number of steps or positions for the time embedding, with a default of 500. This
        is used in the sinusoidal time embedding.
        - time_emb_dim (int, optional): The dimensionality of the time embedding vector, with a default of 100.
        
        Raises:
        - ValueError: If the &#39;size&#39; parameter is not recognized (i.e., not 128 or 256), a ValueError is raised.
        
        The network comprises several stages of downsampling followed by upsampling to create a symmetric architecture,
        with additional bottleneck layers. Time-dependent features are integrated at multiple levels of the network.
        &#34;&#34;&#34;
        super(MyUNet, self).__init__()
        self.size = size

        # Sinusoidal embedding
        self.time_embed = nn.Embedding(n_steps, time_emb_dim)
        self.time_embed.weight.data = sinusoidal_embedding(n_steps, time_emb_dim)
        self.time_embed.requires_grad_(False)
        
        
        if self.size == 128:
            # First half
            self.te1 = self._make_te(time_emb_dim, channel)
            self.b1 = nn.Sequential(
                MyBlock((channel, 128, 128), channel, 16),
                MyBlock((16, 128, 128), 16, 16)
            )
            self.down1 = nn.Conv2d(16, 32, 4, 2, 1) # 128x128 --&gt; 64x64

            self.te2 = self._make_te(time_emb_dim, 32)
            self.b2 = nn.Sequential(
                MyBlock((32, 64, 64), 32, 32),
                MyBlock((32, 64, 64), 32, 32)
            )
            self.down2 = nn.Conv2d(32, 64, 4, 2, 1) # 64x64 --&gt; 32x32

            self.te3 = self._make_te(time_emb_dim, 64)
            self.b3 = nn.Sequential(
                MyBlock((64, 32, 32), 64, 64),
                MyBlock((64, 32, 32), 64, 64)
            )
            self.down3 = nn.Conv2d(64, 128, 4, 2, 1) # 32x32 --&gt; 16x16

            self.te4 = self._make_te(time_emb_dim, 128)
            self.b4 = nn.Sequential(
                MyBlock((128, 16, 16), 128, 128),
                MyBlock((128, 16, 16), 128, 128)
            )
            self.down4 = nn.Conv2d(128, 256, 4, 2, 1) # 16x16 --&gt; 8x8

            self.te5 = self._make_te(time_emb_dim, 256)
            self.b5 = nn.Sequential(
                MyBlock((256, 8, 8), 256, 256),
                MyBlock((256, 8, 8), 256, 256)
            )
            self.down5 = nn.Sequential(
                nn.Conv2d(256, 256, 2, 1), # 8x8 --&gt; 7x7
                nn.SiLU(),
                nn.Conv2d(256, 512, 4, 2, 2) # 7x7 --&gt; 4x4
            )

            # Bottleneck
            self.te_mid = self._make_te(time_emb_dim, 512)
            self.b_mid = nn.Sequential(
                MyBlock((512, 4, 4), 512, 512),
                MyBlock((512, 4, 4), 512, 512),
                MyBlock((512, 4, 4), 512, 512)
            )

            # Second half
            self.up1 = nn.Sequential(
                nn.ConvTranspose2d(512, 512, 3, 2, 1), #4x4 --&gt; 7x7
                nn.SiLU(),
                nn.ConvTranspose2d(512, 256, 2, 1) #7x7 --&gt; 8x8
            )

            self.te7 = self._make_te(time_emb_dim, 512)
            self.b7 = nn.Sequential(
                MyBlock((512, 8, 8), 512, 256),
                MyBlock((256, 8, 8), 256, 128),
                MyBlock((128, 8, 8), 128, 128)
            )

            self.up2 = nn.ConvTranspose2d(128, 128, 4, 2, 1) #8x8 --&gt; 16x16
            self.te8 = self._make_te(time_emb_dim, 256)
            self.b8 = nn.Sequential(
                MyBlock((256, 16, 16), 256, 128),
                MyBlock((128, 16, 16), 128, 64),
                MyBlock((64, 16, 16), 64, 64)
            )

            self.up3 = nn.ConvTranspose2d(64, 64, 4, 2, 1) #16x16 --&gt; 32x32
            self.te9 = self._make_te(time_emb_dim, 128)
            self.b9 = nn.Sequential(
                MyBlock((128, 32, 32), 128, 64),
                MyBlock((64, 32, 32), 64, 32),
                MyBlock((32, 32, 32), 32, 32, normalize=False)
            )

            self.up4 = nn.ConvTranspose2d(32, 32, 4, 2, 1) #32x32 --&gt; 64x64
            self.te10 = self._make_te(time_emb_dim, 64) # 64 (out3) + 22 = 86
            self.b10 = nn.Sequential(
                MyBlock((64, 64, 64), 64, 32),
                MyBlock((32, 64, 64), 32, 16),
                MyBlock((16, 64, 64), 16, 16, normalize=False)
            )

            self.up5 = nn.ConvTranspose2d(16, 16, 4, 2, 1) #64x64 --&gt; 128x128
            self.te11 = self._make_te(time_emb_dim, 32) # 32 (out2) + 21 = 53
            self.b11 = nn.Sequential(
                MyBlock((32, 128, 128), 32, 16),
                MyBlock((16, 128, 128), 16, 8),
                MyBlock((8, 128, 128), 8, 8, normalize=False)
            )

            self.conv_out = nn.Conv2d(8, channel, 3, 1, 1)
        
        elif self.size == 256:
            # First half
            self.te1 = self._make_te(time_emb_dim, channel)
            self.b1 = nn.Sequential(
                MyBlock((channel, 256, 256), channel, 16),
                MyBlock((16, 256, 256), 16, 16)
            )
            self.down1 = nn.Conv2d(16, 32, 4, 2, 1) # 256x256 --&gt; 128x128

            self.te2 = self._make_te(time_emb_dim, 32)
            self.b2 = nn.Sequential(
                MyBlock((32, 128, 128), 32, 32),
                MyBlock((32, 128, 128), 32, 32)
            )
            self.down2 = nn.Conv2d(32, 64, 4, 2, 1) # 128x128 --&gt; 64x64

            self.te3 = self._make_te(time_emb_dim, 64)
            self.b3 = nn.Sequential(
                MyBlock((64, 64, 64), 64, 64),
                MyBlock((64, 64, 64), 64, 64)
            )
            self.down3 = nn.Conv2d(64, 128, 4, 2, 1) # 64x64 --&gt; 32x32

            self.te4 = self._make_te(time_emb_dim, 128)
            self.b4 = nn.Sequential(
                MyBlock((128, 32, 32), 128, 128),
                MyBlock((128, 32, 32), 128, 128)
            )
            self.down4 = nn.Conv2d(128, 256, 4, 2, 1) # 32x32 --&gt; 16x16
            
            self.te5 = self._make_te(time_emb_dim, 256)
            self.b5 = nn.Sequential(
                MyBlock((256, 16, 16), 256, 256),
                MyBlock((256, 16, 16), 256, 256)
            )
            self.down5 = nn.Conv2d(256, 512, 4, 2, 1) # 16x16 --&gt; 8x8

            self.te6 = self._make_te(time_emb_dim, 512)
            self.b6 = nn.Sequential(
                MyBlock((512, 8, 8), 512, 512),
                MyBlock((512, 8, 8), 512, 512)
            )
            self.down6 = nn.Sequential(
                nn.Conv2d(512, 512, 2, 1), # 8x8 --&gt; 7x7
                nn.SiLU(),
                nn.Conv2d(512, 1024, 4, 2, 2) # 7x7 --&gt; 4x4
            )

            # Bottleneck
            self.te_mid = self._make_te(time_emb_dim, 1024)
            self.b_mid = nn.Sequential(
                MyBlock((1024, 4, 4), 1024, 1024),
                MyBlock((1024, 4, 4), 1024, 1024),
                MyBlock((1024, 4, 4), 1024, 1024)
            )

            # Second half
            self.up1 = nn.Sequential(
                nn.ConvTranspose2d(1024, 512, 3, 2, 1), #4x4 --&gt; 7x7
                nn.SiLU(),
                nn.ConvTranspose2d(512, 512, 2, 1) #7x7 --&gt; 8x8
            )

            self.te7 = self._make_te(time_emb_dim, 1024)
            self.b7 = nn.Sequential(
                MyBlock((1024, 8, 8), 1024, 512),
                MyBlock((512, 8, 8), 512, 256),
                MyBlock((256, 8, 8), 256, 256)
            )

            self.up2 = nn.ConvTranspose2d(256, 256, 4, 2, 1) #8x8 --&gt; 16x16
            self.te8 = self._make_te(time_emb_dim, 512)
            self.b8 = nn.Sequential(
                MyBlock((512, 16, 16), 512, 256),
                MyBlock((256, 16, 16), 256, 128),
                MyBlock((128, 16, 16), 128, 128)
            )

            self.up3 = nn.ConvTranspose2d(128, 128, 4, 2, 1) #16x16 --&gt; 32x32
            self.te9 = self._make_te(time_emb_dim, 256)
            self.b9 = nn.Sequential(
                MyBlock((256, 32, 32), 256, 128),
                MyBlock((128, 32, 32), 128, 64),
                MyBlock((64, 32, 32), 64, 64, normalize=False)
            )

            self.up4 = nn.ConvTranspose2d(64, 64, 4, 2, 1) #32x32 --&gt; 64x64
            self.te10 = self._make_te(time_emb_dim, 128) # 64 (out3) + 22 = 86
            self.b10 = nn.Sequential(
                MyBlock((128, 64, 64), 128, 64),
                MyBlock((64, 64, 64), 64, 32),
                MyBlock((32, 64, 64), 32, 32, normalize=False)
            )

            self.up5 = nn.ConvTranspose2d(32, 32, 4, 2, 1) #64x64 --&gt; 128x128
            self.te11 = self._make_te(time_emb_dim, 64) # 32 (out2) + 21 = 53
            self.b11 = nn.Sequential(
                MyBlock((64, 128, 128), 64, 32),
                MyBlock((32, 128, 128), 32, 16),
                MyBlock((16, 128, 128), 16, 16, normalize=False)
            )
            
            self.up6 = nn.ConvTranspose2d(16, 16, 4, 2, 1) #64x64 --&gt; 128x128
            self.te12 = self._make_te(time_emb_dim, 32) # 32 (out2) + 21 = 53
            self.b12 = nn.Sequential(
                MyBlock((32, 256, 256), 32, 16),
                MyBlock((16, 256, 256), 16, 8),
                MyBlock((8, 256, 256), 8, 8, normalize=False)
            )

            self.conv_out = nn.Conv2d(8, channel, 3, 1, 1)
            
        else: 
            print(f&#34;Wrong size : {self.size}&#34;)

    def forward(self, x, t):
        &#34;&#34;&#34;
        Forward pass of the model.

        Args:
            x (torch.Tensor): The input tensor.
            t (torch.Tensor): The time tensor.

        Returns:
            torch.Tensor: The output tensor after passing through the model.
        &#34;&#34;&#34;
        t = self.time_embed(t)
        n = len(x)
        if self.size == 128:
            out1 = self.b1(x + self.te1(t).reshape(n, -1, 1, 1))        
            out2 = self.b2(self.down1(out1) + self.te2(t).reshape(n, -1, 1, 1))        
            out3 = self.b3(self.down2(out2) + self.te3(t).reshape(n, -1, 1, 1))        
            out4 = self.b4(self.down3(out3) + self.te4(t).reshape(n, -1, 1, 1))        
            out5 = self.b5(self.down4(out4) + self.te5(t).reshape(n, -1, 1, 1))
            
            out_mid = self.b_mid(self.down5(out5) + self.te_mid(t).reshape(n, -1, 1, 1))

            out7 = torch.cat((out5, self.up1(out_mid)), dim=1)
            out7 = self.b7(out7 + self.te7(t).reshape(n, -1, 1, 1))

            out8 = torch.cat((out4, self.up2(out7)), dim=1)
            out8 = self.b8(out8 + self.te8(t).reshape(n, -1, 1, 1))

            out9 = torch.cat((out3, self.up3(out8)), dim=1)
            out9 = self.b9(out9 + self.te9(t).reshape(n, -1, 1, 1))

            out10 = torch.cat((out2, self.up4(out9)), dim=1)
            out10 = self.b10(out10 + self.te10(t).reshape(n, -1, 1, 1))

            out11 = torch.cat((out1, self.up5(out10)), dim=1)
            out = self.b11(out11 + self.te11(t).reshape(n, -1, 1, 1))

            out = self.conv_out(out)

            return out
        
        elif self.size == 256:
            out1 = self.b1(x + self.te1(t).reshape(n, -1, 1, 1))        
            out2 = self.b2(self.down1(out1) + self.te2(t).reshape(n, -1, 1, 1))        
            out3 = self.b3(self.down2(out2) + self.te3(t).reshape(n, -1, 1, 1))        
            out4 = self.b4(self.down3(out3) + self.te4(t).reshape(n, -1, 1, 1))        
            out5 = self.b5(self.down4(out4) + self.te5(t).reshape(n, -1, 1, 1))
            out6 = self.b6(self.down5(out5) + self.te6(t).reshape(n, -1, 1, 1))
            
            out_mid = self.b_mid(self.down6(out6) + self.te_mid(t).reshape(n, -1, 1, 1))

            out7 = torch.cat((out6, self.up1(out_mid)), dim=1)
            out7 = self.b7(out7 + self.te7(t).reshape(n, -1, 1, 1))

            out8 = torch.cat((out5, self.up2(out7)), dim=1)
            out8 = self.b8(out8 + self.te8(t).reshape(n, -1, 1, 1))

            out9 = torch.cat((out4, self.up3(out8)), dim=1)
            out9 = self.b9(out9 + self.te9(t).reshape(n, -1, 1, 1))

            out10 = torch.cat((out3, self.up4(out9)), dim=1)
            out10 = self.b10(out10 + self.te10(t).reshape(n, -1, 1, 1))

            out11 = torch.cat((out2, self.up5(out10)), dim=1)
            out11 = self.b11(out11 + self.te11(t).reshape(n, -1, 1, 1))
            
            out12 = torch.cat((out1, self.up6(out11)), dim=1)
            out = self.b12(out12 + self.te12(t).reshape(n, -1, 1, 1))

            out = self.conv_out(out)

            return out

    def _make_te(self, dim_in, dim_out):
        &#34;&#34;&#34;
        Creates a sequential neural network model with two linear layers and a SiLU activation function.

        Args:
            dim_in (int): The number of input features.
            dim_out (int): The number of output features.

        Returns:
            torch.nn.Sequential: The sequential neural network model.
        &#34;&#34;&#34;
        return nn.Sequential(
            nn.Linear(dim_in, dim_out),
            nn.SiLU(),
            nn.Linear(dim_out, dim_out)
        )</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="unet.MyUNet.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, x, t) ‑> Callable[..., Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Forward pass of the model.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>torch.Tensor</code></dt>
<dd>The input tensor.</dd>
<dt><strong><code>t</code></strong> :&ensp;<code>torch.Tensor</code></dt>
<dd>The time tensor.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>torch.Tensor</code></dt>
<dd>The output tensor after passing through the model.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward(self, x, t):
    &#34;&#34;&#34;
    Forward pass of the model.

    Args:
        x (torch.Tensor): The input tensor.
        t (torch.Tensor): The time tensor.

    Returns:
        torch.Tensor: The output tensor after passing through the model.
    &#34;&#34;&#34;
    t = self.time_embed(t)
    n = len(x)
    if self.size == 128:
        out1 = self.b1(x + self.te1(t).reshape(n, -1, 1, 1))        
        out2 = self.b2(self.down1(out1) + self.te2(t).reshape(n, -1, 1, 1))        
        out3 = self.b3(self.down2(out2) + self.te3(t).reshape(n, -1, 1, 1))        
        out4 = self.b4(self.down3(out3) + self.te4(t).reshape(n, -1, 1, 1))        
        out5 = self.b5(self.down4(out4) + self.te5(t).reshape(n, -1, 1, 1))
        
        out_mid = self.b_mid(self.down5(out5) + self.te_mid(t).reshape(n, -1, 1, 1))

        out7 = torch.cat((out5, self.up1(out_mid)), dim=1)
        out7 = self.b7(out7 + self.te7(t).reshape(n, -1, 1, 1))

        out8 = torch.cat((out4, self.up2(out7)), dim=1)
        out8 = self.b8(out8 + self.te8(t).reshape(n, -1, 1, 1))

        out9 = torch.cat((out3, self.up3(out8)), dim=1)
        out9 = self.b9(out9 + self.te9(t).reshape(n, -1, 1, 1))

        out10 = torch.cat((out2, self.up4(out9)), dim=1)
        out10 = self.b10(out10 + self.te10(t).reshape(n, -1, 1, 1))

        out11 = torch.cat((out1, self.up5(out10)), dim=1)
        out = self.b11(out11 + self.te11(t).reshape(n, -1, 1, 1))

        out = self.conv_out(out)

        return out
    
    elif self.size == 256:
        out1 = self.b1(x + self.te1(t).reshape(n, -1, 1, 1))        
        out2 = self.b2(self.down1(out1) + self.te2(t).reshape(n, -1, 1, 1))        
        out3 = self.b3(self.down2(out2) + self.te3(t).reshape(n, -1, 1, 1))        
        out4 = self.b4(self.down3(out3) + self.te4(t).reshape(n, -1, 1, 1))        
        out5 = self.b5(self.down4(out4) + self.te5(t).reshape(n, -1, 1, 1))
        out6 = self.b6(self.down5(out5) + self.te6(t).reshape(n, -1, 1, 1))
        
        out_mid = self.b_mid(self.down6(out6) + self.te_mid(t).reshape(n, -1, 1, 1))

        out7 = torch.cat((out6, self.up1(out_mid)), dim=1)
        out7 = self.b7(out7 + self.te7(t).reshape(n, -1, 1, 1))

        out8 = torch.cat((out5, self.up2(out7)), dim=1)
        out8 = self.b8(out8 + self.te8(t).reshape(n, -1, 1, 1))

        out9 = torch.cat((out4, self.up3(out8)), dim=1)
        out9 = self.b9(out9 + self.te9(t).reshape(n, -1, 1, 1))

        out10 = torch.cat((out3, self.up4(out9)), dim=1)
        out10 = self.b10(out10 + self.te10(t).reshape(n, -1, 1, 1))

        out11 = torch.cat((out2, self.up5(out10)), dim=1)
        out11 = self.b11(out11 + self.te11(t).reshape(n, -1, 1, 1))
        
        out12 = torch.cat((out1, self.up6(out11)), dim=1)
        out = self.b12(out12 + self.te12(t).reshape(n, -1, 1, 1))

        out = self.conv_out(out)

        return out</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="unet.sinusoidal_embedding" href="#unet.sinusoidal_embedding">sinusoidal_embedding</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="unet.MyBlock" href="#unet.MyBlock">MyBlock</a></code></h4>
<ul class="">
<li><code><a title="unet.MyBlock.forward" href="#unet.MyBlock.forward">forward</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="unet.MyUNet" href="#unet.MyUNet">MyUNet</a></code></h4>
<ul class="">
<li><code><a title="unet.MyUNet.forward" href="#unet.MyUNet.forward">forward</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>